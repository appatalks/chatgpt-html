// Javascript
// For OpenAI API

// API Call for latest gpt classes
function trboSend() {

  // Remove occurrences of the specific syntax from the txtMsg element
	txtMsg.innerHTML = txtMsg.innerHTML.replace(/<img\b[^>]*>/g, '');

  var sQuestion = txtMsg.innerHTML;
    sQuestion = sQuestion.replace(/<br>/g, "\n");
  if (sQuestion.trim() == "") {
    alert("Type in your question!");
    txtMsg.focus();
    return;
  }

  var oHttp = new XMLHttpRequest();
  oHttp.open("POST", "https://api.openai.com/v1/chat/completions");
    oHttp.setRequestHeader("Accept", "application/json");
    oHttp.setRequestHeader("Content-Type", "application/json");
    oHttp.setRequestHeader("Authorization", "Bearer " + OPENAI_API_KEY)

    // Error Handling - Needs more testing
    oHttp.onreadystatechange = async function () {
        if (oHttp.readyState === 4) {
    	  // Check for errors
    	  if (oHttp.status === 500) {
      	    txtOutput.innerHTML += "<br> Error 500: Internal Server Error" + "<br>" + oHttp.responseText;
      	    console.log("Error 500: Internal Server Error gpt-core.js");
      	    return;
    	  }
    	  if (oHttp.status === 429) {
      	    txtOutput.innerHTML += "<br> Error 429: Too Many Requests" + "<br>" + oHttp.responseText;
            console.log("Error 429: Too Many Requests gpt-core.js");
      	    return;
    	  }
          if (oHttp.status === 404) {
            txtOutput.innerHTML += "<br> Error 404: Not Found" + "<br>" + oHttp.responseText;
            console.log("Error 404: Not Found gpt-core.js");
            return;
          }
          if (oHttp.status === 400) {
            txtOutput.innerHTML += "<br> Error 400: Invalid Request" + "<br>" + oHttp.responseText;
            console.log("Error 400: Invalid Request gpt-core.js");
            return;
          }
            //console.log(oHttp.status);
            var oJson = {}
            try {
                oJson = JSON.parse(oHttp.responseText);  // API Response Data
            } catch (ex) {
                txtOutput.innerHTML += "Error: " + ex.message;
		console.log("Error: gpt-core.js JSON parse");
		return;
              }
	
	// EasterEgg
	if ((oJson.usage.completion_tokens === 420) || (oJson.usage.total_tokens === 420)) {
          function displayImage() {
	      var image = document.getElementById("eEgg");
	      image.style.display = "flex";
	      setTimeout(function() {
	        image.style.opacity = 1;
  	      }, 50);
  	      setTimeout(function() {
    		image.style.opacity = 0;
  	      }, 2420);
  	      setTimeout(function() {
    		image.style.display = "none";
  	      }, 2920);
           }
          displayImage();
        }
	
	// Timeout Error Exponetial Backoff 
        if (oJson.error && oJson.error.message) {
	    if (oJson.error.message == "overloaded" && retryCount < maxRetries) {
                retryCount++;
                var retryDelay = Math.pow(2, retryCount) * 1000;
                console.log("Too busy. Retrying in " + retryDelay + "ms");
                setTimeout(trboSend, retryDelay);
                return;
            }
	    else {
                txtOutput.innerHTML += "Error Other: " + oJson.error.message;
	        console.log("Error Other: gpt-core.js Line 89");
                retryCount = 0;	  
	    }
       	}
	
	// Interpret AI Response after Error Handling
	else if (oJson.choices && oJson.choices[0].message) {
	    // console.log("gpt-core.js Line 96" + oJson.choices + "" + oJson.choices[0].message);
	    // Always Run Response 
            var s = oJson.choices[0].message;
	    // Empty Response Handling / Render via unified renderer
	    await renderEvaResponse(s.content, txtOutput);
       	
            // Send to Local Storage - possibly way to intigrate into memory
	    let outputWithoutTags = txtOutput.innerText + "\n";
	    masterOutput += outputWithoutTags;
	    localStorage.setItem("masterOutput", masterOutput);
	    
	    // Set lastResponse
	    lastResponse = s.content + "\n";
            // console.log("gpt-core.js Line 152" + lastResponse);
            }            
        }

  	// Check the state of the checkbox and have fun
	   const checkbox = document.getElementById("autoSpeak");
	   if (checkbox.checked) {
	     speakText();
    	     const audio = document.getElementById("audioPlayback");
	     audio.setAttribute("autoplay", true);
	   }
    };

    // payload parameters
    var sModel = selModel.value; 
    var iMaxTokens = (typeof getModelMaxTokens === 'function') ? getModelMaxTokens() : 4096;
  var dTemperature = (typeof getModelTemperature === 'function') ? getModelTemperature() : 0.7; 
    var eFrequency_penalty = 0.0; 
    var cPresence_penalty = 0.0; 
    var hStop = "&*&"; 
  var topP = 1.0; // Optional nucleus sampling

  // Model flags
  var isGpt5 = (sModel && sModel.indexOf('gpt-5') === 0);
  var isLatest = (sModel === 'latest');

    // Messages payload
    // Check if the messages item exists in localStorage
    if (!localStorage.getItem("messages")) {
      // If it does not exist, create an array with the initial messages
      const iMessages = [
        { role: 'developer', content: 'You are Eva. You have access to previous chats and responses. You have access to real-time news, information and media. You will keep conversation to a minimum and answer to the best of your abilities. When you are asked to show an image, instead describe the image with [Image of <Description>].' },
        { role: 'user', content: ((typeof getSystemPrompt === 'function') ? getSystemPrompt() : '') + " " + dateContents },
      ];

      // Store the initial messages in localStorage
      localStorage.setItem("messages", JSON.stringify(iMessages));
    }

    // Create a new array to store the messages
    let newMessages = [];

	//const cleanedQuestion = sQuestion.replace(/<div[^>]*>|<\/div>|&nbsp;/gi, '');
	const cleanedQuestion = sQuestion.replace(/<div[^>]*>|<\/div>|&nbsp;|<span[^>]*>|<\/span>/gi, '');

    	// Push the messages to the new array
    	newMessages.push({ role: 'assistant', content: lastResponse.replace(/\n/g, ' ') });
	newMessages.push({ role: 'user', content: cleanedQuestion.replace(/\n/g, '') });

      	// External Sources
	// Check external.js for source data

	// Weather Report
        const keyword_weather = 'weather';
        if (sQuestion.includes(keyword_weather)) {
          newMessages.push({ role: 'user', content: "Today's " + weatherContents + ". " + sQuestion.replace(/\n/g, '') });
        }

        // Top Headline News
        const keyword_news = 'news';
        if (sQuestion.includes(keyword_news)) {
          newMessages.push({ role: 'user', content: "Today's " + newsContents + ". " + sQuestion.replace(/\n/g, '') });
        }

        // Markets
        const keyword_stock = 'stock';
        const keyword_markets = 'markets';
        const keyword_spy = 'SPY';
        if (sQuestion.includes(keyword_stock) || sQuestion.includes(keyword_markets) || sQuestion.includes(keyword_spy)) {
          newMessages.push({ role: 'user', content: "Today's " + marketContents + " " + sQuestion.replace(/\n/g, '') });
        }

        // Solar Space Weather
        const keyword_solar = 'solar';
        const keyword_spaceweather = 'space weather';
        if (sQuestion.includes(keyword_solar) || sQuestion.includes(keyword_spaceweather)) {
          newMessages.push({ role: 'user', content: "Today's " + solarContents + " " + sQuestion.replace(/\n/g, '') });
        }

    // Append the new messages to the existing messages in localStorage
    let existingMessages = JSON.parse(localStorage.getItem("messages")) || [];
    existingMessages = existingMessages.concat(newMessages);
    localStorage.setItem("messages", JSON.stringify(existingMessages));

    // Retrieve messages from local storage
    var cStoredMessages = localStorage.getItem("messages");
    var kMessages = cStoredMessages ? JSON.parse(cStoredMessages) : [];

        // Exclude messages with the "developer" role see 
        // https://github.com/appatalks/chatgpt-html/issues/63#issuecomment-2492821202 
        if (sModel === 'o1-preview' || sModel === 'o1-mini') {
          kMessages = kMessages.filter(msg => msg.role === 'user' || msg.role === 'assistant');
          dTemperature = 1;
        }
  // Potential gpt-5 guidance (adjust if OpenAI docs require different roles)
  // Keep roles for now; gpt-5 uses default temperature only; do not override.
	
    // API Payload
    var data = {
        model: sModel,
	messages: kMessages,
        max_completion_tokens: iMaxTokens,
        temperature:  dTemperature,
        frequency_penalty: eFrequency_penalty,
        presence_penalty: cPresence_penalty,
	stop: hStop
    }
            // Additional parameters for GPT-5 family and 'latest' alias
            if (isGpt5 || isLatest) {
              data.top_p = topP;
              // Do not send max_tokens for gpt-5; use max_completion_tokens only
              delete data.temperature; // Exclude temperature for gpt-5/latest
              delete data.stop; // Exclude stop for gpt-5/latest
            }
    if (sModel === "o3-mini") {
      data.reasoning_effort = (typeof getReasoningEffort === 'function') ? getReasoningEffort() : "medium";
      delete data.temperature; // Exclude temperature for o3-mini
    }   

    // Sending API Payload
    oHttp.send(JSON.stringify(data));
    // console.log("gpt-core.js Line 330" + JSON.stringify(data));

    // Relay Send to Screen

  if (imgSrcGlobal) {
    var responseImage = document.createElement("img");
    responseImage.src = imgSrcGlobal;
  // no leading newline to avoid extra gaps
    // Wrap user message in bubble
    const userWrap = document.createElement('div');
    userWrap.className = 'chat-bubble user-bubble';
    const safeUserImg = (function escapeHtmlLite(str){
      return String(str)
        .replace(/&/g, '&amp;')
        .replace(/</g, '&lt;')
        .replace(/>/g, '&gt;')
        .replace(/"/g, '&quot;')
        .replace(/'/g, '&#39;');
    })(sQuestion.replace(/<br>/g, '\n')).replace(/\n/g, '<br>');
    userWrap.innerHTML = '<span class="user">You:</span> ' + safeUserImg;
    userWrap.appendChild(responseImage);
    txtOutput.appendChild(userWrap);
  } else {
    // Sanitize user HTML to avoid breaking the bubble but preserve line breaks
    const safeUser = (function escapeHtmlLite(str){
      return String(str)
        .replace(/&/g, '&amp;')
        .replace(/</g, '&lt;')
        .replace(/>/g, '&gt;')
        .replace(/"/g, '&quot;')
        .replace(/'/g, '&#39;');
    })(sQuestion.replace(/<br>/g, '\n'))
      .replace(/\n/g, '<br>');
    txtOutput.innerHTML += '<div class="chat-bubble user-bubble">' + '<span class="user">You:</span> ' + safeUser + '</div>';
    txtMsg.innerHTML = "";
    var element = document.getElementById("txtOutput");
    element.scrollTop = element.scrollHeight;
  }
  imgSrcGlobal = '';
}
